{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/pollen_data.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Pannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class acc_callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        if (logs.get('val_acc')>=.95):\n",
    "            print('Validation Accuracy has reached 95%')\n",
    "            print('Ending epochs')\n",
    "            self.model.stop_training=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructure Image Layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I plan to use TensorFlow's Image Generator, and the images have to be seperated into a specific folder layout. \n",
    "\n",
    "This function Takes all of the images and puts them into the proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'Data/images'\n",
    "def split_to_train_and_val(df,img_dir):\n",
    "    train, test = train_test_split(df)\n",
    "\n",
    "    train_pol = train[train['pollen_carrying'] == 1]\n",
    "    test_pol = test[test['pollen_carrying'] == 1]\n",
    "\n",
    "    train_no = train[train['pollen_carrying'] == 0]\n",
    "    test_no = test[test['pollen_carrying'] == 0]\n",
    "\n",
    "\n",
    "    groups = [\n",
    "          {'data':train_pol,'dir':'Training/has_pollen'},\n",
    "         {'data':test_pol,'dir':'Validation/has_pollen'},\n",
    "          {'data':train_no,'dir':'Training/no_pollen'},\n",
    "         {'data':test_no,'dir':'Validation/no_pollen'},\n",
    "    ]\n",
    "\n",
    "\n",
    "    for group in groups:\n",
    "        os.system(f\"mkdir -p {img_dir}/{group['dir']}\")\n",
    "\n",
    "        for file in group['data']['filename']:\n",
    "            os.system(f\"cp {img_dir}/{file} {img_dir}/{group['dir']}/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this to create directories for Train and Val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_to_train_and_val(df,img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Image generators to read in Data from Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 535 images belonging to 2 classes.\n",
      "Found 179 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Data/images/Training',\n",
    "        target_size=img_size, #img_size is set in the Control Pannel at the top  \n",
    "        batch_size=128,\n",
    "        class_mode='binary')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        'Data/images/Validation',\n",
    "        target_size=img_size,\n",
    "        batch_size=28,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Sequential Conv NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0625 13:28:32.854012 140288735053440 deprecation.py:506] From /home/snorks/dev/ml/ds-projects/bees/venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2)),\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2)),\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile our model using binary crossentropy since we are dealing with has pollen or no pollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 13:28:33.026495 140288735053440 deprecation.py:323] From /home/snorks/dev/ml/ds-projects/bees/venv/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Callback object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a call back that checks val_acc to end the training once we hit 99% acc\n",
    "If we don't hit 99% on our val data, we will cycle through 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_acc = acc_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.8803 - acc: 0.5491 - val_loss: 0.6673 - val_acc: 0.6618\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6649 - acc: 0.6148 - val_loss: 0.6850 - val_acc: 0.5169\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.6355 - acc: 0.6229 - val_loss: 0.8826 - val_acc: 0.5556\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.5818 - acc: 0.7187 - val_loss: 0.5251 - val_acc: 0.8019\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.5661 - acc: 0.7138 - val_loss: 0.7816 - val_acc: 0.6087\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.5691 - acc: 0.7506 - val_loss: 0.4591 - val_acc: 0.8116\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.3532 - acc: 0.8509 - val_loss: 0.3856 - val_acc: 0.8213\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.4025 - acc: 0.8489 - val_loss: 0.5426 - val_acc: 0.7826\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.2994 - acc: 0.8857 - val_loss: 0.2562 - val_acc: 0.8841\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.2617 - acc: 0.8747 - val_loss: 0.2514 - val_acc: 0.9082\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.1836 - acc: 0.9260 - val_loss: 0.2001 - val_acc: 0.9130\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.1619 - acc: 0.9435 - val_loss: 0.2705 - val_acc: 0.9179\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.1378 - acc: 0.9447 - val_loss: 0.2313 - val_acc: 0.8986\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.1080 - acc: 0.9570 - val_loss: 0.4044 - val_acc: 0.8357\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.1333 - acc: 0.9467 - val_loss: 0.1609 - val_acc: 0.9420\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.0694 - acc: 0.9717 - val_loss: 0.2340 - val_acc: 0.9324\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.2466 - acc: 0.8894 - val_loss: 0.2027 - val_acc: 0.9372\n",
      "Epoch 18/200\n",
      "7/8 [=========================>....] - ETA: 2s - loss: 0.0548 - acc: 0.9781Validation Accuracy has reached 95%\n",
      "Ending epochs\n",
      "8/8 [==============================] - 18s 2s/step - loss: 0.0550 - acc: 0.9779 - val_loss: 0.1452 - val_acc: 0.9565\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,  \n",
    "      epochs=200,\n",
    "      verbose=1,\n",
    "      validation_data = val_generator,\n",
    "      validation_steps=8,\n",
    "      callbacks=[cb_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
